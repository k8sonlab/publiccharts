backend:
  # -- Replica counts
  replicaCount: 1
  # -- Annotations
  annotations: {}
  # -- Using recreate strategy, as this helps to run only one container at a time
  updateStrategyType: Recreate
  image:
    # -- Repository and image name
    repository: reallibrephotos/librephotos
  resources:
    limits:
      memory: 8Gi
    requests:
      cpu: 10m
      memory: 50Mi
  env:
    DEBUG: "0"
    HEAVYWEIGHT_PROCESS: "2"
    SKIP_PATTERNS: ""
    WEB_CONCURRENCY: "4"
    DB_BACKEND: "postgresql"
    ALLOW_UPLOAD: "false"
  envTemplates:
    # -- redis port retrieved by parent helm chart
    redisPort: "{{ .Values.redis.master.containerPorts.redis }}"
    # -- Postgresql DB Name
    dbName: "{{ .Values.postgresql.auth.database }}"
    # -- Postgresql DB port
    dbPort: "{{ .Values.postgresql.containerPorts.postgresql }}"
    # -- Postgresql DB password
    dbUser: "{{ .Values.postgresql.auth.database }}"
  healthchecks:
    livenessProbe:
      tcpSocket:
        port: 8001
      initialDelaySeconds: 10
      failureThreshold: 5
      timeoutSeconds: 5
      periodSeconds: 120
    readinessProbe:
      tcpSocket:
        port: 8001
      initialDelaySeconds: 10
      failureThreshold: 5
      timeoutSeconds: 5
      periodSeconds: 120
    startupProbe:
      tcpSocket:
        port: 8001
      initialDelaySeconds: 10
      failureThreshold: 60
      timeoutSeconds: 2
      periodSeconds: 5

frontend:
  replicaCount: 1
  updateStrategyType: RollingUpdate
  annotations: {}
  image:
    repository: reallibrephotos/librephotos-frontend
  healthchecks:
    livenessProbe:
      tcpSocket:
        port: 3000
      initialDelaySeconds: 10
      failureThreshold: 5
      timeoutSeconds: 5
      periodSeconds: 120
    readinessProbe:
      tcpSocket:
        port: 3000
      initialDelaySeconds: 10
      failureThreshold: 5
      timeoutSeconds: 5
      periodSeconds: 120
    startupProbe:
      tcpSocket:
        port: 3000
      initialDelaySeconds: 10
      failureThreshold: 60
      timeoutSeconds: 2
      periodSeconds: 5
proxy:
  replicaCount: 1
  updateStrategyType: RollingUpdate
  annotations: {}
  image:
    repository: reallibrephotos/librephotos-proxy
  healthchecks:
    livenessProbe:
      tcpSocket:
        port: 80 
      initialDelaySeconds: 10
      failureThreshold: 5
      timeoutSeconds: 5
      periodSeconds: 60
    readinessProbe:
      httpGet:
        path: /
        port: 80 
      initialDelaySeconds: 10
      failureThreshold: 5
      timeoutSeconds: 5
      periodSeconds: 60
    startupProbe:
      tcpSocket:
        port: 80 
      initialDelaySeconds: 10
      failureThreshold: 60
      timeoutSeconds: 2
      periodSeconds: 5

service:
  backend:
    type: ClusterIP
    ports:
      - port: 80
        targetPort: 8001
        protocol: TCP
        name: backend
    annotations: {}
  frontend:
    type: ClusterIP
    ports:
      - port: 80
        targetPort: 3000
        protocol: TCP
        name: backend
    annotations: {}
  proxy:
    type: ClusterIP
    ports:
      - port: 80
        targetPort: 80
        protocol: TCP
        name: backend
    annotations: {}

secret:
  ADMIN_EMAIL: "admin@mydomain.com"
  ADMIN_USERNAME: "admin"
  ADMIN_PASSWORD: "password"
  MAPBOX_API_KEY: ""

cronjob:
  # -- Create a native kubernetes cronjob, using roles to access kubernetes exec and execute the python through a third party container. This is an Antipattern! but the only way, till another exists
  type: native
  native:
    # -- Annotations for the cronjog
    annotations: {}
    # -- Cronjob schedule
    schedule: "0 * * * *"
    # -- concurrency policy, Forbid as default, to avoid running two scans
    concurrencyPolicy: Forbid
    # -- keep 10 jobs for log parsing (if they fail
    failedJobsHistoryLimit: 10
    # -- keep 5 successful jobs for log parsing.
    successfulJobHistoryLimit: 5
    image:
      imagePullPolicy: IfNotPresent
      # -- Check alpine image for the latest available https://hub.docker.com/r/alpine/k8s/tags
      kubernetesVersion: "1.22.6"

nameOverride: ""
fullnameOverride: ""

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    add: []
    drop: []
  privileged: false
  readOnlyRootFilesystem: false
  runAsNonRoot: false

ingress:
  # -- enable ingress 
  enabled: false
  annotations: {}
  # -- currently only hotsname is needed for ingress
  hostname: ""
  # -- Configure TLS for the ingress. Both secretName and hosts can process a Helm template.
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

dataVolume:
  # -- Size of the volume to be created (data)
  size: 100Gi
  # -- Access mode of volume
  accessModes: 
   - "ReadWriteOnce"
  # -- Storage class of data volume
  stroageClass: ""
# to be refactored
volumes:
  # -- Shared volume, as emptyDir
  - name: shared
    emptyDir:
      {}
  # -- temporary folder in Memory
  - name: temp
    emptyDir:
      medium: Memory
  # -- logs in emptyDir
  - name: varlogs
    emptyDir:
      {}

# -- You can define extra volumes, in the typical K8s syntax (Only in backend)
extraVolumes:

# -- You can define extra volume mounts, in the typical K8s syntax (Only in backend)
extraVolumeMounts:

# Postgresql
postgresql:
  # -- install bitnami postgresql
  enabled: true
  auth:
    username: librephotos
    database: librephotos
redis:
  # -- install bitnami redis
  enabled: true
  architecture: standalone
  master:
    disableCommands:
      - FLUSHALL
